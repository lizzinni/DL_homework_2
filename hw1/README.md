# Домашнее задание - 1 (Поиск информативного скрытого слоя в LLMs)

### Задача:
Исследовать распределение информации внутри слоев большой языковой модели (LLM) и определить, какие слои дают наилучшие представления для выбранной задачи (классификация, регрессия или любая другая прикладная цель). Метод основан на идеях A* публикации (HiProbe-VAD), где показано, что наиболее информативные признаки часто находятся в промежуточных слоях модели

### Инструкция:
1. Определить LLM, исходя из доступных вычислительных ресурсов
2. Выбрать корпус (акустический, визуальный, текстовый или мультимодальный), подходящий под задачу
3. Прогнать данные через модель. Для каждого слоя получить нужные представления.
4. Доказать через метрики и визуализацию, какие слои лучшие (тут можно свое авторское придумать и попробовать)
5. На представлениях разных слоев (например топ-3) обучить простой классификатор или регрессор
6. Построить графики/визуализации - номер слоя -> метрика/метрики качества
7. Сделать заключение о том, какие слои оказались наиболее информативными и почему. Сравните промежуточные, начальные и финальные слои.

### В итоге
- Код экспериментов (ноутбук или py с полным pipeline)
- Таблица и график с результатами по слоям
- Выводы о том, где в LLM сосредоточены лучшие признаки для выбранной задачи.

Ссылка на статью: https://arxiv.org/abs/2509.01337